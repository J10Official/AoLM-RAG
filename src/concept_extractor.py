"""
Concept extractor module using OpenRouter API.
Extracts atomic concepts from lecture transcripts using LLMs.
"""
import json
import time
import re
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, asdict
from openai import OpenAI


# ============================================================================
# PROMPT DESIGN FOR ATOMIC CONCEPT EXTRACTION
# ============================================================================
# 
# Goals:
# 1. ATOMIC: Each concept should be indivisible (single idea, not compound)
# 2. MERGEABLE: Standardized naming + keywords for later deduplication
# 3. EDUCATIONAL: Focus on teachable concepts, not lecture logistics
# 4. HIERARCHICAL: Capture both fundamental and applied concepts
#
# The prompt uses a structured JSON output for reliability.
# ============================================================================

SYSTEM_PROMPT = """You are an expert knowledge engineer specializing in extracting atomic educational concepts from lecture transcripts.

Your task is to identify and extract ATOMIC CONCEPTS - single, indivisible units of knowledge that:
1. Represent ONE specific idea, term, principle, formula, or technique
2. Can stand alone as a learnable unit
3. Have a clear, standardized name (use established terminology when possible)
4. Are relevant to the subject matter (ignore logistics, greetings, repetitions)

For each concept, provide:
- `name`: A canonical, standardized name (noun phrase, title case, 2-6 words)
- `description`: One clear sentence explaining what it is (not how it's used in the lecture)
- `keywords`: 3-5 lowercase keywords for matching/merging with related concepts
- `category`: One of: definition, principle, formula, technique, example, fact, relationship

IMPORTANT GUIDELINES:
- Extract 10-30 concepts per lecture segment (quality over quantity)
- Use STANDARD terminology (e.g., "Bernoulli's Principle" not "the pressure thing")
- Avoid duplicates - if a concept is mentioned multiple times, extract it once
- Focus on DOMAIN KNOWLEDGE, not meta-commentary about the lecture
- For formulas, include the formula name not the equation itself
- Keywords should help merge this concept with the same concept from other lectures

Output ONLY valid JSON array. No markdown, no explanation."""

USER_PROMPT_TEMPLATE = """Extract atomic concepts from this lecture transcript.

LECTURE: {lecture_name}
COURSE: {course_name}
DISCIPLINE: {discipline}

TRANSCRIPT:
{transcript}

Return a JSON array of concepts. Example format:
[
  {{
    "name": "Lift Coefficient",
    "description": "A dimensionless number that relates the lift generated by an airfoil to fluid density, velocity, and reference area.",
    "keywords": ["lift", "coefficient", "aerodynamics", "airfoil", "dimensionless"],
    "category": "definition"
  }},
  {{
    "name": "Bernoulli's Principle",
    "description": "States that an increase in fluid velocity occurs simultaneously with a decrease in pressure or potential energy.",
    "keywords": ["bernoulli", "pressure", "velocity", "fluid", "energy"],
    "category": "principle"
  }}
]

Extract concepts now:"""


@dataclass
class Concept:
    """Represents an atomic concept extracted from a lecture."""
    name: str
    description: str
    keywords: List[str]
    category: str
    confidence: float = 1.0
    source_lecture_id: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any], source_lecture_id: str = "") -> 'Concept':
        return cls(
            name=data.get('name', ''),
            description=data.get('description', ''),
            keywords=data.get('keywords', []),
            category=data.get('category', 'definition'),
            confidence=data.get('confidence', 1.0),
            source_lecture_id=source_lecture_id
        )


class OpenRouterClient:
    """Client for OpenRouter API (OpenAI-compatible)."""
    
    def __init__(
        self,
        api_key: str,
        default_model: str = "meta-llama/llama-3.3-70b-instruct:free",
        base_url: str = "https://openrouter.ai/api/v1"
    ):
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url,
            default_headers={
                "HTTP-Referer": "https://github.com/nptel-graph-rag",
                "X-Title": "NPTEL Graph RAG"
            }
        )
        self.default_model = default_model
        
        # Model configurations
        self.models = {
            "deepseek": "deepseek/deepseek-r1-0528:free",
            "llama": "meta-llama/llama-3.3-70b-instruct:free",
            "qwen": "qwen/qwen3-next-80b-a3b-instruct:free"
        }
    
    def complete(
        self,
        prompt: str,
        system_prompt: str = "",
        model: Optional[str] = None,
        max_tokens: int = 4096,
        temperature: float = 0.3,
        extra_body: Optional[Dict] = None
    ) -> str:
        """
        Send a completion request to OpenRouter.
        
        Args:
            prompt: User prompt
            system_prompt: System prompt
            model: Model to use (defaults to self.default_model)
            max_tokens: Maximum tokens in response
            temperature: Sampling temperature
            extra_body: Additional parameters (e.g., provider preferences)
            
        Returns:
            Model response text
        """
        model = model or self.default_model
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        kwargs = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
        }
        
        # Add provider preferences for llama model
        if "llama" in model.lower():
            kwargs["extra_body"] = {
                "provider": {
                    "order": ["open-inference/int8"]
                }
            }
        
        if extra_body:
            kwargs["extra_body"] = {**kwargs.get("extra_body", {}), **extra_body}
        
        response = self.client.chat.completions.create(**kwargs)
        return response.choices[0].message.content


class ConceptExtractor:
    """
    Extracts atomic concepts from lecture transcripts using LLMs.
    """
    
    def __init__(self, api_key: str, model: str = "llama"):
        """
        Initialize the concept extractor.
        
        Args:
            api_key: OpenRouter API key
            model: Model shorthand ("deepseek", "llama", or "qwen")
        """
        self.client = OpenRouterClient(api_key)
        
        # Select model
        if model in self.client.models:
            self.model = self.client.models[model]
        else:
            self.model = model
            
        print(f"Using model: {self.model}")
    
    def extract_concepts(
        self,
        transcript: str,
        lecture_name: str,
        course_name: str,
        discipline: str,
        lecture_id: str = "",
        max_retries: int = 3
    ) -> List[Concept]:
        """
        Extract atomic concepts from a lecture transcript.
        
        Args:
            transcript: Full transcript text
            lecture_name: Name of the lecture
            course_name: Name of the course
            discipline: Academic discipline
            lecture_id: ID for tracking source
            max_retries: Number of retries on failure
            
        Returns:
            List of extracted Concept objects
        """
        # Build prompt
        prompt = USER_PROMPT_TEMPLATE.format(
            lecture_name=lecture_name,
            course_name=course_name,
            discipline=discipline,
            transcript=transcript[:80000]  # Limit transcript length
        )
        
        for attempt in range(max_retries):
            try:
                # Call LLM
                response = self.client.complete(
                    prompt=prompt,
                    system_prompt=SYSTEM_PROMPT,
                    model=self.model,
                    max_tokens=4096,
                    temperature=0.3
                )
                
                # Parse JSON response
                concepts = self._parse_response(response, lecture_id)
                
                if concepts:
                    return concepts
                    
            except json.JSONDecodeError as e:
                print(f"  JSON parse error (attempt {attempt + 1}): {e}")
            except Exception as e:
                print(f"  Error (attempt {attempt + 1}): {e}")
                
            # Wait before retry
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # Exponential backoff
        
        return []
    
    def _parse_response(self, response: str, lecture_id: str) -> List[Concept]:
        """Parse LLM response into Concept objects."""
        # Clean response - remove markdown code blocks if present
        response = response.strip()
        if response.startswith("```"):
            # Remove markdown code block
            response = re.sub(r'^```(?:json)?\n?', '', response)
            response = re.sub(r'\n?```$', '', response)
        
        # Find JSON array in response
        match = re.search(r'\[[\s\S]*\]', response)
        if not match:
            raise json.JSONDecodeError("No JSON array found", response, 0)
        
        json_str = match.group(0)
        data = json.loads(json_str)
        
        concepts = []
        for item in data:
            if isinstance(item, dict) and 'name' in item:
                concept = Concept.from_dict(item, source_lecture_id=lecture_id)
                # Validate
                if concept.name and concept.description:
                    concepts.append(concept)
        
        return concepts
    
    def extract_from_chunks(
        self,
        chunks: List[str],
        lecture_name: str,
        course_name: str,
        discipline: str,
        lecture_id: str = ""
    ) -> List[Concept]:
        """
        Extract concepts from multiple transcript chunks and deduplicate.
        
        Args:
            chunks: List of transcript chunks
            lecture_name: Name of the lecture
            course_name: Name of the course
            discipline: Academic discipline
            lecture_id: ID for tracking source
            
        Returns:
            Deduplicated list of Concept objects
        """
        all_concepts = []
        
        for i, chunk in enumerate(chunks):
            print(f"    Processing chunk {i + 1}/{len(chunks)}...")
            concepts = self.extract_concepts(
                transcript=chunk,
                lecture_name=lecture_name,
                course_name=course_name,
                discipline=discipline,
                lecture_id=lecture_id
            )
            all_concepts.extend(concepts)
        
        # Deduplicate by name (case-insensitive)
        seen = {}
        unique_concepts = []
        for concept in all_concepts:
            key = concept.name.lower().strip()
            if key not in seen:
                seen[key] = concept
                unique_concepts.append(concept)
        
        return unique_concepts


if __name__ == '__main__':
    # Test the concept extractor
    import sys
    sys.path.insert(0, str(__file__).rsplit('/', 2)[0])
    
    from src.transcript_fetcher import get_transcript
    
    # API key (replace with your key)
    API_KEY = "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"
    
    # Test video
    test_url = "https://www.youtube.com/watch?v=eP9WqeDjsCc"  # Lecture 2
    
    print("Fetching transcript...")
    transcript, error = get_transcript(test_url)
    
    if error:
        print(f"Error: {error}")
        exit(1)
    
    print(f"Transcript: {transcript.word_count} words, ~{transcript.estimated_tokens} tokens")
    
    # Extract concepts
    print("\nExtracting concepts...")
    extractor = ConceptExtractor(api_key=API_KEY, model="llama")
    
    concepts = extractor.extract_concepts(
        transcript=transcript.full_text,
        lecture_name="Lecture 2: Introduction to Civil Aviation",
        course_name="Air Transportation: An Overview",
        discipline="Aerospace Engineering",
        lecture_id="test_lecture"
    )
    
    print(f"\nExtracted {len(concepts)} concepts:")
    for c in concepts[:10]:
        print(f"\n  [{c.category}] {c.name}")
        print(f"    {c.description}")
        print(f"    Keywords: {', '.join(c.keywords)}")
